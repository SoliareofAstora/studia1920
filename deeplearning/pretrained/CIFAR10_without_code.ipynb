{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_without_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "pycharm-e230bcc",
      "language": "python",
      "display_name": "PyCharm (deeplearning)"
    },
    "accelerator": "GPU",
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVclo602PoY0",
        "colab_type": "text"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Train on GPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "1. On the main menu, click Runtime and select **Change runtime type**. Set \"GPU\" as the hardware accelerator.\n",
        "1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "vKyUMIUzEuei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "4e6f31e5-6751-4613-ca43-7a1ec920fed2"
      },
      "source": [
        "import keras\n",
        "keras.__version__\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLjbWVSwLRAM",
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l1_b4FLnAx",
        "colab_type": "code",
        "outputId": "849a5389-f206-430b-8468-d7adf918aef1",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "pcefAGXUEufF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODIFY THE CODE TO ADD A VALIDATION SET\n",
        "validation_count = 2500\n",
        "\n",
        "train_images = train_images.reshape((50000, 32, 32, 3))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "validation_images = train_images[:validation_count]\n",
        "train_images = train_images[validation_count:]\n",
        "\n",
        "test_images = test_images.reshape((10000, 32, 32, 3))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "validation_labels = train_labels[:validation_count]\n",
        "train_labels = train_labels[validation_count:]\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "tF0HBHS-EufN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "cb19fa97-1804-4955-9ed7-36fe0d241489"
      },
      "source": [
        "backbone = keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
        "backbone.trainable = False"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "a8PWENZQEufV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d91b4552-1ad8-4573-fe5f-fc770d4ce6cc"
      },
      "source": [
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "def extract(images):\n",
        "    output = []\n",
        "    with tqdm.tqdm(total=images.shape[0]) as pbar:\n",
        "        for image in images:\n",
        "            img = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC).reshape(1,224,224,3)\n",
        "            output.append(backbone.predict(img))\n",
        "            pbar.update(1)\n",
        "    return output\n",
        "\n",
        "test_images = np.concatenate(extract(test_images))\n",
        "train_images = np.concatenate(extract(train_images))\n",
        "validation_images = np.concatenate(extract(validation_images))\n",
        "# backbone.predict(test_images)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [03:02<00:00, 54.91it/s]\n",
            "100%|██████████| 47500/47500 [13:53<00:00, 56.97it/s]\n",
            "100%|██████████| 2500/2500 [00:43<00:00, 58.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIJilTuvRnDY",
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6538f43a-697c-4715-8017-231c0f089ae2"
      },
      "source": [
        "# MAKE WHATEVER CHANGES ARE NECESSARY\n",
        "# TO GET 0.7 ACCURACY ON THE TEST SET\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1000, activation='relu',input_shape=[1000]))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr0xkEliYc-6",
        "colab_type": "code",
        "outputId": "6897d91a-dd48-48fe-8a73-e717568b7858",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 1,011,010\n",
            "Trainable params: 1,011,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdgz18QPNOVr",
        "colab_type": "code",
        "outputId": "5775abb6-0fe0-4653-a3f3-a52794d57d84",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  # MAKE WHATEVER CHANGES ARE NECESSARY\n",
        "  # TO GET 0.7 ACCURACY ON THE TEST SET\n",
        "epichs = 100\n",
        "model_hist = model.fit(train_images, train_labels,\n",
        "                       validation_data=(validation_images,validation_labels),\n",
        "                        epochs=epichs, batch_size=500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 47500 samples, validate on 2500 samples\n",
            "Epoch 1/100\n",
            "47500/47500 [==============================] - 2s 43us/step - loss: 1.6653 - acc: 0.5459 - val_loss: 1.1749 - val_acc: 0.6140\n",
            "Epoch 2/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 1.0744 - acc: 0.6382 - val_loss: 1.0186 - val_acc: 0.6488\n",
            "Epoch 3/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.9748 - acc: 0.6693 - val_loss: 0.9562 - val_acc: 0.6712\n",
            "Epoch 4/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.9225 - acc: 0.6884 - val_loss: 0.9236 - val_acc: 0.6936\n",
            "Epoch 5/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.8868 - acc: 0.7002 - val_loss: 0.9001 - val_acc: 0.6952\n",
            "Epoch 6/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.8593 - acc: 0.7098 - val_loss: 0.8850 - val_acc: 0.7072\n",
            "Epoch 7/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.8361 - acc: 0.7167 - val_loss: 0.8645 - val_acc: 0.7160\n",
            "Epoch 8/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.8168 - acc: 0.7243 - val_loss: 0.8497 - val_acc: 0.7180\n",
            "Epoch 9/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7984 - acc: 0.7289 - val_loss: 0.8365 - val_acc: 0.7212\n",
            "Epoch 10/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7829 - acc: 0.7346 - val_loss: 0.8299 - val_acc: 0.7200\n",
            "Epoch 11/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7688 - acc: 0.7388 - val_loss: 0.8186 - val_acc: 0.7248\n",
            "Epoch 12/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7558 - acc: 0.7435 - val_loss: 0.8075 - val_acc: 0.7284\n",
            "Epoch 13/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7426 - acc: 0.7472 - val_loss: 0.8077 - val_acc: 0.7268\n",
            "Epoch 14/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.7321 - acc: 0.7500 - val_loss: 0.7929 - val_acc: 0.7384\n",
            "Epoch 15/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7202 - acc: 0.7544 - val_loss: 0.7860 - val_acc: 0.7416\n",
            "Epoch 16/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.7110 - acc: 0.7565 - val_loss: 0.7843 - val_acc: 0.7444\n",
            "Epoch 17/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.7007 - acc: 0.7597 - val_loss: 0.7789 - val_acc: 0.7440\n",
            "Epoch 18/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6927 - acc: 0.7635 - val_loss: 0.7695 - val_acc: 0.7468\n",
            "Epoch 19/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6833 - acc: 0.7658 - val_loss: 0.7636 - val_acc: 0.7488\n",
            "Epoch 20/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6756 - acc: 0.7675 - val_loss: 0.7622 - val_acc: 0.7468\n",
            "Epoch 21/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6671 - acc: 0.7697 - val_loss: 0.7566 - val_acc: 0.7548\n",
            "Epoch 22/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6591 - acc: 0.7731 - val_loss: 0.7527 - val_acc: 0.7548\n",
            "Epoch 23/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6525 - acc: 0.7757 - val_loss: 0.7481 - val_acc: 0.7548\n",
            "Epoch 24/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6453 - acc: 0.7777 - val_loss: 0.7456 - val_acc: 0.7564\n",
            "Epoch 25/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6382 - acc: 0.7798 - val_loss: 0.7424 - val_acc: 0.7612\n",
            "Epoch 26/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6318 - acc: 0.7843 - val_loss: 0.7401 - val_acc: 0.7588\n",
            "Epoch 27/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6247 - acc: 0.7851 - val_loss: 0.7365 - val_acc: 0.7568\n",
            "Epoch 28/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6185 - acc: 0.7868 - val_loss: 0.7330 - val_acc: 0.7640\n",
            "Epoch 29/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6133 - acc: 0.7884 - val_loss: 0.7296 - val_acc: 0.7616\n",
            "Epoch 30/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.6074 - acc: 0.7913 - val_loss: 0.7336 - val_acc: 0.7644\n",
            "Epoch 31/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.6014 - acc: 0.7935 - val_loss: 0.7278 - val_acc: 0.7640\n",
            "Epoch 32/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5950 - acc: 0.7963 - val_loss: 0.7239 - val_acc: 0.7664\n",
            "Epoch 33/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5900 - acc: 0.7967 - val_loss: 0.7202 - val_acc: 0.7644\n",
            "Epoch 34/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5846 - acc: 0.7993 - val_loss: 0.7180 - val_acc: 0.7672\n",
            "Epoch 35/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5793 - acc: 0.7997 - val_loss: 0.7196 - val_acc: 0.7640\n",
            "Epoch 36/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5749 - acc: 0.8021 - val_loss: 0.7151 - val_acc: 0.7668\n",
            "Epoch 37/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5694 - acc: 0.8040 - val_loss: 0.7136 - val_acc: 0.7668\n",
            "Epoch 38/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5645 - acc: 0.8056 - val_loss: 0.7157 - val_acc: 0.7672\n",
            "Epoch 39/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5597 - acc: 0.8069 - val_loss: 0.7109 - val_acc: 0.7688\n",
            "Epoch 40/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5548 - acc: 0.8089 - val_loss: 0.7101 - val_acc: 0.7672\n",
            "Epoch 41/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5494 - acc: 0.8110 - val_loss: 0.7144 - val_acc: 0.7644\n",
            "Epoch 42/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5465 - acc: 0.8118 - val_loss: 0.7106 - val_acc: 0.7744\n",
            "Epoch 43/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5414 - acc: 0.8122 - val_loss: 0.7062 - val_acc: 0.7720\n",
            "Epoch 44/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5360 - acc: 0.8141 - val_loss: 0.7053 - val_acc: 0.7728\n",
            "Epoch 45/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5323 - acc: 0.8168 - val_loss: 0.7053 - val_acc: 0.7700\n",
            "Epoch 46/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5274 - acc: 0.8182 - val_loss: 0.7049 - val_acc: 0.7740\n",
            "Epoch 47/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5224 - acc: 0.8206 - val_loss: 0.7057 - val_acc: 0.7704\n",
            "Epoch 48/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5192 - acc: 0.8206 - val_loss: 0.7036 - val_acc: 0.7752\n",
            "Epoch 49/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.5145 - acc: 0.8224 - val_loss: 0.7043 - val_acc: 0.7692\n",
            "Epoch 50/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5108 - acc: 0.8241 - val_loss: 0.6994 - val_acc: 0.7728\n",
            "Epoch 51/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5060 - acc: 0.8254 - val_loss: 0.6982 - val_acc: 0.7740\n",
            "Epoch 52/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.5018 - acc: 0.8273 - val_loss: 0.7018 - val_acc: 0.7788\n",
            "Epoch 53/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4973 - acc: 0.8278 - val_loss: 0.6970 - val_acc: 0.7816\n",
            "Epoch 54/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4955 - acc: 0.8285 - val_loss: 0.7025 - val_acc: 0.7712\n",
            "Epoch 55/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4900 - acc: 0.8303 - val_loss: 0.6994 - val_acc: 0.7736\n",
            "Epoch 56/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4860 - acc: 0.8334 - val_loss: 0.7025 - val_acc: 0.7700\n",
            "Epoch 57/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4835 - acc: 0.8343 - val_loss: 0.6968 - val_acc: 0.7728\n",
            "Epoch 58/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4785 - acc: 0.8354 - val_loss: 0.6950 - val_acc: 0.7776\n",
            "Epoch 59/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4747 - acc: 0.8371 - val_loss: 0.6980 - val_acc: 0.7728\n",
            "Epoch 60/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4712 - acc: 0.8379 - val_loss: 0.6965 - val_acc: 0.7764\n",
            "Epoch 61/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4670 - acc: 0.8391 - val_loss: 0.6946 - val_acc: 0.7788\n",
            "Epoch 62/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4637 - acc: 0.8410 - val_loss: 0.6994 - val_acc: 0.7796\n",
            "Epoch 63/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4605 - acc: 0.8416 - val_loss: 0.6952 - val_acc: 0.7816\n",
            "Epoch 64/100\n",
            "47500/47500 [==============================] - 0s 11us/step - loss: 0.4565 - acc: 0.8429 - val_loss: 0.7011 - val_acc: 0.7760\n",
            "Epoch 65/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4524 - acc: 0.8451 - val_loss: 0.6958 - val_acc: 0.7780\n",
            "Epoch 66/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4485 - acc: 0.8465 - val_loss: 0.6917 - val_acc: 0.7808\n",
            "Epoch 67/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4462 - acc: 0.8485 - val_loss: 0.6958 - val_acc: 0.7788\n",
            "Epoch 68/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4426 - acc: 0.8500 - val_loss: 0.7016 - val_acc: 0.7764\n",
            "Epoch 69/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4390 - acc: 0.8504 - val_loss: 0.6963 - val_acc: 0.7820\n",
            "Epoch 70/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4363 - acc: 0.8519 - val_loss: 0.6928 - val_acc: 0.7824\n",
            "Epoch 71/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4323 - acc: 0.8524 - val_loss: 0.6985 - val_acc: 0.7788\n",
            "Epoch 72/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4298 - acc: 0.8539 - val_loss: 0.6926 - val_acc: 0.7800\n",
            "Epoch 73/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4252 - acc: 0.8564 - val_loss: 0.7004 - val_acc: 0.7800\n",
            "Epoch 74/100\n",
            "47500/47500 [==============================] - 0s 11us/step - loss: 0.4219 - acc: 0.8584 - val_loss: 0.6963 - val_acc: 0.7820\n",
            "Epoch 75/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4188 - acc: 0.8585 - val_loss: 0.6967 - val_acc: 0.7780\n",
            "Epoch 76/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4160 - acc: 0.8590 - val_loss: 0.6944 - val_acc: 0.7812\n",
            "Epoch 77/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4129 - acc: 0.8606 - val_loss: 0.7064 - val_acc: 0.7768\n",
            "Epoch 78/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4096 - acc: 0.8613 - val_loss: 0.6958 - val_acc: 0.7824\n",
            "Epoch 79/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4061 - acc: 0.8631 - val_loss: 0.6986 - val_acc: 0.7820\n",
            "Epoch 80/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.4033 - acc: 0.8653 - val_loss: 0.7070 - val_acc: 0.7776\n",
            "Epoch 81/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.4006 - acc: 0.8647 - val_loss: 0.6993 - val_acc: 0.7820\n",
            "Epoch 82/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3975 - acc: 0.8669 - val_loss: 0.7027 - val_acc: 0.7840\n",
            "Epoch 83/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.3939 - acc: 0.8682 - val_loss: 0.6993 - val_acc: 0.7848\n",
            "Epoch 84/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3909 - acc: 0.8688 - val_loss: 0.6996 - val_acc: 0.7800\n",
            "Epoch 85/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3880 - acc: 0.8701 - val_loss: 0.6997 - val_acc: 0.7816\n",
            "Epoch 86/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3848 - acc: 0.8714 - val_loss: 0.7068 - val_acc: 0.7844\n",
            "Epoch 87/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.3822 - acc: 0.8732 - val_loss: 0.7030 - val_acc: 0.7812\n",
            "Epoch 88/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3787 - acc: 0.8740 - val_loss: 0.7048 - val_acc: 0.7848\n",
            "Epoch 89/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3766 - acc: 0.8733 - val_loss: 0.6980 - val_acc: 0.7864\n",
            "Epoch 90/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3742 - acc: 0.8740 - val_loss: 0.7064 - val_acc: 0.7840\n",
            "Epoch 91/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3713 - acc: 0.8764 - val_loss: 0.7106 - val_acc: 0.7812\n",
            "Epoch 92/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3674 - acc: 0.8780 - val_loss: 0.7049 - val_acc: 0.7828\n",
            "Epoch 93/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3644 - acc: 0.8793 - val_loss: 0.7056 - val_acc: 0.7836\n",
            "Epoch 94/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.3624 - acc: 0.8797 - val_loss: 0.7112 - val_acc: 0.7772\n",
            "Epoch 95/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3595 - acc: 0.8813 - val_loss: 0.7098 - val_acc: 0.7816\n",
            "Epoch 96/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3560 - acc: 0.8821 - val_loss: 0.7081 - val_acc: 0.7836\n",
            "Epoch 97/100\n",
            "47500/47500 [==============================] - 0s 10us/step - loss: 0.3542 - acc: 0.8833 - val_loss: 0.7106 - val_acc: 0.7836\n",
            "Epoch 98/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3521 - acc: 0.8845 - val_loss: 0.7253 - val_acc: 0.7848\n",
            "Epoch 99/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3494 - acc: 0.8852 - val_loss: 0.7112 - val_acc: 0.7816\n",
            "Epoch 100/100\n",
            "47500/47500 [==============================] - 1s 11us/step - loss: 0.3459 - acc: 0.8859 - val_loss: 0.7198 - val_acc: 0.7800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK7GvOCaUwp9",
        "colab_type": "code",
        "outputId": "0d3359b5-6787-43a4-ed8a-930db9762015",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, epichs)\n",
        "train_loss = model_hist.history['loss']\n",
        "val_loss= model_hist.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, val_loss, 'b+', label='Validation')\n",
        "plt.plot(epochs, train_loss, 'bo', label='training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngkBEJOUUBCIiKacgEBFJOQWBiEjK/X9/q5Sj72rukgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSr5gnDLNRo7",
        "colab_type": "code",
        "outputId": "f52ec8a5-8da4-4187-ebdc-fd88f2c926f0",
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)\n",
        "test_loss"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 50us/step\n",
            "test_acc: 0.7803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7103838948726654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9SeN6QOO77D",
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "model.save_weights('./cifar10.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WkigYULHEugI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}